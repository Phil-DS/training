{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Term Rentals - Data Import\n",
    "\n",
    "We're going to work with a short term rentals dataset that we got from [InsideAirbnb](http://insideairbnb.com/). We'll be using Neo4j via the popular py2neo library.\n",
    "\n",
    "We'll start by importing py2neo and the pandas library which we'll be using to play around with the data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"bolt://localhost\", auth=(\"neo4j\", \"neo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some variables for our import CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listings_file = \"https://guides.neo4j.com/listings/data/nyc/listings.csv.gz\"\n",
    "# reviews_file = \"https://guides.neo4j.com/listings/data/nyc/reviews.csv.gz\"\n",
    "\n",
    "listings_file = \"file:///listings.csv.gz\"\n",
    "reviews_file = \"file:///reviews.csv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to load the data into Neo4j. This is the graph that we want to create:\n",
    "\n",
    "\"arrows diagram here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels_added': 50914, 'nodes_created': 50914, 'properties_set': 450338}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraint_query = \"\"\"\n",
    "CREATE CONSTRAINT ON (l:Listing)\n",
    "ASSERT l.id IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "import_query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM $listingsFile AS row\n",
    "WITH row WHERE row.id IS NOT NULL\n",
    "MERGE (l:Listing {id: row.id})\n",
    "SET l.name = row.name,\n",
    "    l.price = toFloat(substring(row.price, 1)),\n",
    "    l.weeklyPrice = toFloat(substring(row.weekly_price, 1)),\n",
    "    l.cleaningFee = toFloat(substring(row.cleaning_fee, 1)),\n",
    "    l.propertyType = row.property_type,\n",
    "    l.accommodates = toInt(row.accommodates),\n",
    "    l.bedrooms = toInt(row.bedrooms),\n",
    "    l.bathrooms = toInt(row.bathrooms),\n",
    "    l.availability365 = toInt(row.availability_365)\n",
    "\"\"\"\n",
    "\n",
    "graph.run(constraint_query).summary().counters\n",
    "graph.run(import_query, {\"listingsFile\": listings_file}).summary().counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels_added': 224, 'relationships_created': 50914, 'nodes_created': 224, 'properties_set': 439}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraint_query = \"\"\"\n",
    "CREATE CONSTRAINT ON (n:Neighborhood) \n",
    "ASSERT n.id IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "import_query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM $listingsFile AS row\n",
    "WITH row WHERE row.id IS NOT NULL\n",
    "MATCH (l:Listing {id: row.id})\n",
    "MERGE (n:Neighborhood {id: coalesce(row.neighbourhood_cleansed, \"NA\")})\n",
    "ON CREATE SET n.name = row.neighbourhood\n",
    "MERGE (l)-[:IN_NEIGHBORHOOD]->(n);\n",
    "\"\"\"\n",
    "\n",
    "graph.run(constraint_query).summary().counters\n",
    "graph.run(import_query, {\"listingsFile\": listings_file}).summary().counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels_added': 127, 'relationships_created': 981512, 'nodes_created': 127, 'properties_set': 127}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraint_query = \"\"\"\n",
    "CREATE CONSTRAINT ON (a:Amenity) \n",
    "ASSERT a.name IS UNIQUE;\n",
    "\"\"\"\n",
    "\n",
    "import_query = \"\"\"\n",
    "USING PERIODIC COMMIT 1000\n",
    "LOAD CSV WITH HEADERS FROM $listingsFile AS row\n",
    "WITH row WHERE row.id IS NOT NULL\n",
    "MATCH (l:Listing {id: row.id})\n",
    "WITH l, split(replace(replace(replace(row.amenities, '{', ''), '}', ''), '\\\"', ''), ',') AS amenities\n",
    "UNWIND amenities AS amenity\n",
    "MERGE (a:Amenity {name: amenity})\n",
    "MERGE (l)-[:HAS]->(a)\n",
    "\"\"\"\n",
    "\n",
    "graph.run(constraint_query).summary().counters\n",
    "graph.run(import_query, {\"listingsFile\": listings_file}).summary().counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels_added': 40309, 'relationships_created': 50914, 'nodes_created': 40309, 'properties_set': 201383}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraint_query = \"\"\"\n",
    "CREATE CONSTRAINT ON (h:Host) \n",
    "ASSERT h.id IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "import_query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM $listingsFile AS row\n",
    "WITH row WHERE row.host_id IS NOT NULL\n",
    "MERGE (h:Host {id: row.host_id})\n",
    "ON CREATE SET h.name      = row.host_name,\n",
    "              h.about     = row.host_abot,\n",
    "              h.superhost = CASE WHEN row.host_is_super_host = \"t\" THEN True ELSE False END,\n",
    "              h.location  = row.host_location,\n",
    "              h.image     = row.host_picture_url\n",
    "WITH row, h\n",
    "MATCH (l:Listing {id: row.id})\n",
    "MERGE (h)-[:HOSTS]->(l);\n",
    "\"\"\"\n",
    "\n",
    "graph.run(constraint_query)\n",
    "graph.run(import_query, {\"listingsFile\": listings_file}).summary().counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels_added': 649493, 'relationships_created': 719078, 'nodes_created': 649493, 'properties_set': 3678110}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_constraint_query = \"\"\"\n",
    "CREATE CONSTRAINT ON (u:User) \n",
    "ASSERT u.id IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "review_constraint_query = \"\"\"\n",
    "CREATE CONSTRAINT ON (r:Review) \n",
    "ASSERT r.id IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import_query = \"\"\"\n",
    "USING PERIODIC COMMIT 10000\n",
    "LOAD CSV WITH HEADERS FROM $reviewsFile AS row\n",
    "\n",
    "// User\n",
    "MERGE (u:User {id: row.reviewer_id})\n",
    "SET u.name = row.reviewer_name\n",
    "\n",
    "// Review\n",
    "MERGE (r:Review {id: row.id})\n",
    "SET r.date     = row.date,\n",
    "    r.comments = row.comments\n",
    "WITH row, u, r\n",
    "MATCH (l:Listing {id: row.listing_id})\n",
    "MERGE (u)-[:WROTE]->(r)\n",
    "MERGE (r)-[:REVIEWS]->(l);\n",
    "\"\"\"\n",
    "\n",
    "graph.run(user_constraint_query).summary().counters\n",
    "graph.run(review_constraint_query).summary().counters\n",
    "graph.run(import_query, {\"reviewsFile\": reviews_file}).summary().counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook we'll explore the data we've imported."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
