{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Term Rentals - Data Import\n",
    "\n",
    "We're going to work with a short term rentals dataset that we got from [InsideAirbnb](http://insideairbnb.com/). We'll be using Neo4j via the popular py2neo library.\n",
    "\n",
    "We'll start by importing py2neo and the pandas library which we'll be using to play around with the data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"bolt://localhost\", auth=(\"neo4j\", \"neo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to load the data into Neo4j. This is the graph model that we want to end up with:\n",
    "\n",
    "<div align=\"left\">\n",
    "    <img src=\"images/graph_model.png\" alt=\"Graph Model\" width=\"500px\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some variables for our import CSV files to simplify our import script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_file = \"https://guides.neo4j.com/listings/data/nyc/listings.csv.gz\"\n",
    "reviews_file = \"https://guides.neo4j.com/listings/data/nyc/reviews.csv.gz\"\n",
    "\n",
    "# listings_file = \"file:///listings.csv.gz\"\n",
    "# reviews_file = \"file:///reviews.csv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use Cypher's LOAD CSV command to process these CSV files and create the graph structure described above. Let's start by having a look what we have in both of these files, starting with the listings file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_listings_csv_query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM $listingsFile AS row\n",
    "RETURN row\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "graph.run(explore_listings_csv_query, {\"listingsFile\": listings_file}).data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the reviews file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_reviews_csv_query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM $reviewsFile AS row\n",
    "RETURN row\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "graph.run(explore_reviews_csv_query, {\"reviewsFile\": reviews_file}).data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try changing `LIMIT 1` if you want to see a few more reviews or listings. \n",
    "\n",
    "Otherwise we're now ready to import the dataset into Neo4j:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_query = \"\"\"\n",
    "CREATE CONSTRAINT ON (l:Listing)\n",
    "ASSERT l.id IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "import_query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM $listingsFile AS row\n",
    "WITH row WHERE row.id IS NOT NULL\n",
    "MERGE (l:Listing {id: row.id})\n",
    "SET l.name = row.name,\n",
    "    l.price = toFloat(substring(row.price, 1)),\n",
    "    l.weeklyPrice = toFloat(substring(row.weekly_price, 1)),\n",
    "    l.cleaningFee = toFloat(substring(row.cleaning_fee, 1)),\n",
    "    l.propertyType = row.property_type,\n",
    "    l.accommodates = toInt(row.accommodates),\n",
    "    l.bedrooms = toInt(row.bedrooms),\n",
    "    l.bathrooms = toInt(row.bathrooms),\n",
    "    l.availability365 = toInt(row.availability_365),\n",
    "    l.location = point({latitude: toFloat(row.latitude), longitude: toFloat(row.longitude)}),\n",
    "    l.roomType = row.room_type\n",
    "\"\"\"\n",
    "\n",
    "display(graph.run(constraint_query).summary().counters)\n",
    "display(graph.run(import_query, {\"listingsFile\": listings_file}).summary().counters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_query = \"\"\"\n",
    "CREATE CONSTRAINT ON (n:Neighborhood) \n",
    "ASSERT n.id IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "import_query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM $listingsFile AS row\n",
    "WITH row WHERE row.id IS NOT NULL\n",
    "MATCH (l:Listing {id: row.id})\n",
    "MERGE (n:Neighborhood {id: coalesce(row.neighbourhood_cleansed, \"NA\")})\n",
    "ON CREATE SET n.name = row.neighbourhood\n",
    "MERGE (l)-[:IN_NEIGHBORHOOD]->(n);\n",
    "\"\"\"\n",
    "\n",
    "graph.run(constraint_query).summary().counters\n",
    "graph.run(import_query, {\"listingsFile\": listings_file}).summary().counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_query = \"\"\"\n",
    "CREATE CONSTRAINT ON (a:Amenity) \n",
    "ASSERT a.name IS UNIQUE;\n",
    "\"\"\"\n",
    "\n",
    "import_query = \"\"\"\n",
    "USING PERIODIC COMMIT 1000\n",
    "LOAD CSV WITH HEADERS FROM $listingsFile AS row\n",
    "WITH row WHERE row.id IS NOT NULL\n",
    "MATCH (l:Listing {id: row.id})\n",
    "WITH l, split(replace(replace(replace(row.amenities, '{', ''), '}', ''), '\\\"', ''), ',') AS amenities\n",
    "UNWIND amenities AS amenity\n",
    "MERGE (a:Amenity {name: amenity})\n",
    "MERGE (l)-[:HAS]->(a)\n",
    "\"\"\"\n",
    "\n",
    "graph.run(constraint_query).summary().counters\n",
    "graph.run(import_query, {\"listingsFile\": listings_file}).summary().counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_query = \"\"\"\n",
    "CREATE CONSTRAINT ON (h:Host) \n",
    "ASSERT h.id IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "import_query = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM $listingsFile AS row\n",
    "WITH row WHERE row.host_id IS NOT NULL\n",
    "MERGE (h:Host {id: row.host_id})\n",
    "ON CREATE SET h.name      = row.host_name,\n",
    "              h.about     = row.host_about,\n",
    "              h.superhost = CASE WHEN row.host_is_super_host = \"t\" THEN True ELSE False END,\n",
    "              h.location  = row.host_location,\n",
    "              h.image     = row.host_picture_url\n",
    "WITH row, h\n",
    "MATCH (l:Listing {id: row.id})\n",
    "MERGE (h)-[:HOSTS]->(l);\n",
    "\"\"\"\n",
    "\n",
    "graph.run(constraint_query)\n",
    "graph.run(import_query, {\"listingsFile\": listings_file}).summary().counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_constraint_query = \"\"\"\n",
    "CREATE CONSTRAINT ON (u:User) \n",
    "ASSERT u.id IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "review_constraint_query = \"\"\"\n",
    "CREATE CONSTRAINT ON (r:Review) \n",
    "ASSERT r.id IS UNIQUE\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import_query = \"\"\"\n",
    "USING PERIODIC COMMIT 10000\n",
    "LOAD CSV WITH HEADERS FROM $reviewsFile AS row\n",
    "\n",
    "// User\n",
    "MERGE (u:User {id: row.reviewer_id})\n",
    "SET u.name = row.reviewer_name\n",
    "\n",
    "// Review\n",
    "MERGE (r:Review {id: row.id})\n",
    "SET r.date     = row.date,\n",
    "    r.comments = row.comments\n",
    "WITH row, u, r\n",
    "MATCH (l:Listing {id: row.listing_id})\n",
    "MERGE (u)-[:WROTE]->(r)\n",
    "MERGE (r)-[:REVIEWS]->(l);\n",
    "\"\"\"\n",
    "\n",
    "graph.run(user_constraint_query).summary().counters\n",
    "graph.run(review_constraint_query).summary().counters\n",
    "graph.run(import_query, {\"reviewsFile\": reviews_file}).summary().counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook we'll explore the data we've imported."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
