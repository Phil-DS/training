{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neo4j-contrib/training/blob/master/data_science/AppliedGraphAlgorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Graph Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install neo4j pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j.v1 import GraphDatabase, basic_auth\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the line of code below to use the IP Address, Bolt Port, and Password of your Sandbox.\n",
    "#driver = GraphDatabase.driver(\"bolt://<IP Address>:<Bolt Port>\", auth=basic_auth(\"neo4j\", \"<Password>\"))\n",
    "\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=basic_auth(\"neo4j\", \"neo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betweenness Centrality\n",
    "\n",
    "Betweenness centrality identifies nodes that are strategically positioned in the network, meaning that information will often travel through that person. Such an intermediary position gives that person power and influence.\n",
    "\n",
    "Betweenness centrality is a raw count of the number of short paths that go through a given node. For example, if a node is located on a bottleneck between two large communities, then it will have high betweenness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "CALL algo.betweenness.stream(\"Character\", \"INTERACTS1\", {direction: \"BOTH\"})\n",
    "YIELD nodeId, centrality\n",
    "MATCH (c:Character) WHERE ID(c) = nodeId\n",
    "RETURN c.name, centrality\n",
    "ORDER BY centrality DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(query)\n",
    "df = pd.DataFrame([dict(record) for record in result])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"centrality\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "CALL algo.betweenness.stream(\"Character\", \"INTERACTS1\", {direction: \"BOTH\"})\n",
    "YIELD nodeId, centrality\n",
    "MATCH (c:Character) WHERE ID(c) = nodeId\n",
    "WITH c, centrality, [(c)-[r:INTERACTS1]-(other) | {character: other.name, weight: r.weight}] AS interactions\n",
    "RETURN c.name, centrality,\n",
    "       apoc.coll.sum([i in interactions | i.weight]) AS totalInteractions,\n",
    "       [i in apoc.coll.reverse(apoc.coll.sortMaps(interactions, 'weight'))[..5] | i.character] as charactersInteractedWith\n",
    "ORDER BY centrality DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    df = pd.DataFrame([dict(record) for record in session.run(query)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"centrality\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"totalInteractions\"], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing betweenness centrality\n",
    "\n",
    "Although the betweenness centrality algorithm runs very quickly on this dataset we wouldn’t usually be running this types of algorithms in the normal request/response flow of a web/mobile app. Instead of that we can store the result of the calculation as a property on the node and then refer to it in future queries.\n",
    "\n",
    "Each of the algorithms has a variant that saves its output to the database rather than returning a stream. Let’s run the betweenness centrality algorithm and store the result as a property named `book1BetweennessCentrality`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "CALL algo.betweenness(\"Character\", \"INTERACTS1\", {direction: \"BOTH\", writeProperty: \"book1BetweennessCentrality\"})\n",
    "\"\"\"\n",
    "with driver.session() as session:\n",
    "    session.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write the following query to find the most influential characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "MATCH (c:Character)\n",
    "RETURN c.name, c.book1BetweennessCentrality AS centrality\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    df = pd.DataFrame([dict(record) for record in session.run(query)])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"centrality\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Betweenness Centrality for books 2-5\n",
    "\n",
    "Now we want to calculate the betweenness centrality for the other books in the series and store the results in the database.\n",
    "\n",
    "* Write queries that call algo.betweenness for the INTERACTS2, INTERACTS3, and INTERACTS45 relationship types.\n",
    "\n",
    "After you’ve done that see if you can write queries to answer the following questions:\n",
    "\n",
    "* Which character had the biggest increase in influence from book 1 to 5?\n",
    "\n",
    "Wh* ich character had the biggest decrease?\n",
    "\n",
    "Bonus question:\n",
    "\n",
    "* Which characters who were in the top 10 influencers in book 1 are also in the top 10 influencers in book 5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page Rank\n",
    "\n",
    "This is another version of weighted degree centrality with a feedback loop. This time, you only get your “fair share” of your neighbor’s importance.\n",
    "\n",
    "i.e. your neighbor’s importance is split between their neighbors, proportional to the number of interactions with that neighbor.\n",
    "\n",
    "Intuitively, PageRank captures how effectively you are taking advantage of your network contacts. In our context, PageRank centrality nicely captures narrative tension. Indeed, major developments occur when two important characters interact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"CALL algo.pageRank('Character', 'INTERACTS1', \n",
    "                              {direction: 'BOTH', writeProperty:'book1PageRank'})\"\"\")\n",
    "    print(result.peek())\n",
    "    \n",
    "    result = session.run(\"\"\"CALL algo.pageRank('Character', 'INTERACTS2', \n",
    "                              {direction: 'BOTH', writeProperty:'book2PageRank'})\"\"\")\n",
    "    print(result.peek()) \n",
    "    \n",
    "    result = session.run(\"\"\"CALL algo.pageRank('Character', 'INTERACTS3', \n",
    "                              {direction: 'BOTH', writeProperty:'book3PageRank'})\"\"\")\n",
    "    print(result.peek())     \n",
    "    \n",
    "    result = session.run(\"\"\"CALL algo.pageRank('Character', 'INTERACTS45', \n",
    "                              {direction: 'BOTH', writeProperty:'book45PageRank'})\"\"\")\n",
    "    print(result.peek())         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "MATCH (c:Character)\n",
    "WITH c, [(c)-[r:INTERACTS1]-(other) | {character: other.name, weight: r.weight}] AS interactions\n",
    "RETURN c.name, c.book1PageRank AS pageRank, c.book1BetweennessCentrality as centrality, \n",
    "       apoc.coll.sum([i in interactions | i.weight]) AS totalInteractions\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    df = pd.DataFrame([dict(record) for record in session.run(query)])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"centrality\"], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"pageRank\"], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll notice that there are some characters who have a high page rank but a very low betweenness centrality score.\n",
    "\n",
    "This suggests that they aren’t necessarily influential in their own right, but are friends with important people. Varys is a good example of a character that fits this profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Detection\n",
    "\n",
    "We can detect communities in our data by running an algorithm which traverses the graph structure to find highly connected subgraphs with fewer connections other other subgraphs.\n",
    "\n",
    "Run the following query to calculate the communities that exist based on interactions across all the books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "CALL algo.labelPropagation(\n",
    "  'MATCH (c:Character) RETURN id(c) as id',\n",
    "  'MATCH (c:Character)-[rel]->(c2) RETURN id(c) as source, id(c2) as target, SUM(rel.weight) as weight',\n",
    "  'OUTGOING',\n",
    "  {graph:'cypher', partitionProperty: 'community', iterations: 10})\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(query)\n",
    "    print(result.peek())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "MATCH (c:Character)\n",
    "WHERE exists(c.community)\n",
    "RETURN c.community AS community, count(*) AS count\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    df = pd.DataFrame([dict(record) for record in session.run(query)])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"count\"], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Communities\n",
    "\n",
    "It’d be good to know who are the influential people in each community. To do that we’ll need to calculate a Page Rank score for each character across all the books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "CALL algo.pageRank(\n",
    "  'MATCH (c:Character) RETURN id(c) as id',\n",
    "  'MATCH (c:Character)-[rel]->(c2) RETURN id(c) as source,id(c2) as target, SUM(rel.weight) as weight',\n",
    "  {graph:'cypher', writeProperty: 'pageRank', iterations: 10})\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(query)\n",
    "    print(result.peek())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "MATCH (c:Character)\n",
    "WHERE exists(c.community)\n",
    "WITH c ORDER BY c.pageRank DESC\n",
    "RETURN c.community as cluster, count(*) AS count, collect(c.name)[0] AS mostInfluential\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    df = pd.DataFrame([dict(record) for record in session.run(query)])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"count\"], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intra-community Page Rank\n",
    "\n",
    "We can also calculate the Page Rank within communities.\n",
    "\n",
    "Run the following query to calculate the page rank for the 2nd largest community:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "MATCH (c:Character) WHERE EXISTS(c.community)\n",
    "WITH c.community AS communityId, COUNT(*) AS count\n",
    "ORDER BY count DESC\n",
    "SKIP 1 LIMIT 1\n",
    "CALL apoc.cypher.doIt(\n",
    "  \"CALL algo.pageRank(\n",
    "    'MATCH (c:Character) WHERE c.community =\" + communityId + \" RETURN id(c) as id',\n",
    "    'MATCH (c:Character)-[rel]->(c2) WHERE c.community =\" + communityId + \" AND c2.community =\" + communityId + \" RETURN id(c) as source,id(c2) as target, sum(rel.weight) as weight',\n",
    "    {graph:'cypher', writeProperty: 'communityPageRank'}) YIELD nodes RETURN count(*)\", {})\n",
    "YIELD value\n",
    "RETURN value\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(query)\n",
    "    print(result.peek())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "MATCH (c:Character) WHERE EXISTS(c.community)\n",
    "WITH c.community AS communityId, COUNT(*) AS count\n",
    "ORDER BY count DESC\n",
    "SKIP 1 LIMIT 1\n",
    "MATCH (c:Character) WHERE c.community = communityId\n",
    "RETURN c.name AS character, c.communityPageRank as pageRank\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    df = pd.DataFrame([dict(record) for record in session.run(query)])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"pageRank\"], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now calculate the intra-community Page Rank for all the communities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "CALL algo.pageRank(\n",
    "  'MATCH (c:Character) WHERE c.community=%d RETURN id(c) as id',\n",
    "  'MATCH (c:Character)-[rel]->(c2) WHERE c.community=%d AND c2.community =%d RETURN id(c) as source,id(c2) as target, sum(rel.weight) as weight',\n",
    "  {graph:'cypher', writeProperty: 'communityPageRank'}) \n",
    "YIELD nodes \n",
    "RETURN count(*)\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    for row in session.run(\"MATCH (c:Character) WHERE EXISTS(c.community) RETURN DISTINCT c.community AS communityId\"):        \n",
    "        community_id = row[\"communityId\"]\n",
    "        session.run(query % (community_id, community_id, community_id))\n",
    "print(\"Page Ranks calculated\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now work out who the most influential people are inside and outside a community:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\\\n",
    "MATCH (c:Character)\n",
    "WHERE exists(c.community)\n",
    "WITH c ORDER BY c.pageRank DESC\n",
    "WITH  c.community as cluster, count(*) AS count, collect(c) AS characters\n",
    "RETURN cluster, count, \n",
    "       apoc.coll.reverse(apoc.coll.sortNodes(characters, \"pageRank\"))[0].name AS overallInfluential,\n",
    "       apoc.coll.reverse(apoc.coll.sortNodes(characters, \"communityPageRank\"))[0].name AS communityInfluential\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    df = pd.DataFrame([dict(record) for record in session.run(query)])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"count\"], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
